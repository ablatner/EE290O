{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "### Due Date: Thursday, September 27, 2018\n",
    "\n",
    "### Getting Started\n",
    "\n",
    "- Training optimal policies / value functions can take very long, so be sure to start solving the problems early to give yourself enough time to finish training everything.\n",
    "- Please save any plots you generate and add them to the notebook. We will not rerun your code for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Modeling Driving Behaviors via Regression\n",
    "\n",
    "In this problem, we will explore the potential of using neural network models to approximate the acceleration (or car-following) behavior of individual vehicles given certain local observations. Specifically, we will try to estiamte the acceleration $a_\\alpha$ of vehicle $\\alpha$ using only information on its bumper-to-bumper gaps with the lead vehicle $s_\\alpha = x_{\\alpha-1} - x_\\alpha$, the speed of the ego vehicle $v_\\alpha$, and the speed of the lead vehicle $v_{\\alpha-1}$. While the majority of this course focuses on sequential decision making tasks, regression problems such as these on deep neural networks may play a significant role in the future of transportation modeling.\n",
    "\n",
    "<img src=\"img/micro_data.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. NGSIM dataset\n",
    "\n",
    "[NGSIM](https://ops.fhwa.dot.gov/trafficanalysistools/ngsim.htm) is a collection of datasets providing microscopic data on vehicles on the US 101 and I-80 for a total set of 6 intervals of 15 min, sampled at 0.1/s. It is one of the largest sets of open-source microscopic (per-vehicle) transportation data, and is a good candidate for modeling human driver behavior.\n",
    "\n",
    "We begin by importing a processed and filtered version of the dataset. In order to do so, go to https://data.transportation.gov/Automobiles/Next-Generation-Simulation-NGSIM-Vehicle-Trajector/8ect-6jqj and export the data as a csv file. You will now have a new csv file called \"Next\\_Generation\\_Simulation\\_\\_NGSIM\\_\\_Vehicle\\_Trajectories\\_and\\_Supporting\\_Data.csv\" containing all the aforementioned data.\n",
    "\n",
    "Feel free to open and review any of this file. `pandas` is a great tool for visualizing data in Python, and we highly recommend you explore it if you haven't in the past. If you do not have `pandas` installed, enter the following command in your terminal.\n",
    "\n",
    "    pip install pandas\n",
    "\n",
    "Once you have installed it, run the below cell to get a clearer visual representation of the data samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>Frame_ID</th>\n",
       "      <th>Total_Frames</th>\n",
       "      <th>Global_Time</th>\n",
       "      <th>Local_X</th>\n",
       "      <th>Local_Y</th>\n",
       "      <th>Global_X</th>\n",
       "      <th>Global_Y</th>\n",
       "      <th>v_length</th>\n",
       "      <th>v_Width</th>\n",
       "      <th>...</th>\n",
       "      <th>D_Zone</th>\n",
       "      <th>Int_ID</th>\n",
       "      <th>Section_ID</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Movement</th>\n",
       "      <th>Preceding</th>\n",
       "      <th>Following</th>\n",
       "      <th>Space_Headway</th>\n",
       "      <th>Time_Headway</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>437</td>\n",
       "      <td>1118846980200</td>\n",
       "      <td>16.467</td>\n",
       "      <td>35.381</td>\n",
       "      <td>6451137.641</td>\n",
       "      <td>1873344.962</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>us-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>437</td>\n",
       "      <td>1118846980300</td>\n",
       "      <td>16.447</td>\n",
       "      <td>39.381</td>\n",
       "      <td>6451140.329</td>\n",
       "      <td>1873342.000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>us-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>437</td>\n",
       "      <td>1118846980400</td>\n",
       "      <td>16.426</td>\n",
       "      <td>43.381</td>\n",
       "      <td>6451143.018</td>\n",
       "      <td>1873339.038</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>us-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>437</td>\n",
       "      <td>1118846980500</td>\n",
       "      <td>16.405</td>\n",
       "      <td>47.380</td>\n",
       "      <td>6451145.706</td>\n",
       "      <td>1873336.077</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>us-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>437</td>\n",
       "      <td>1118846980600</td>\n",
       "      <td>16.385</td>\n",
       "      <td>51.381</td>\n",
       "      <td>6451148.395</td>\n",
       "      <td>1873333.115</td>\n",
       "      <td>14.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>us-101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vehicle_ID  Frame_ID  Total_Frames    Global_Time  Local_X  Local_Y  \\\n",
       "0           2        13           437  1118846980200   16.467   35.381   \n",
       "1           2        14           437  1118846980300   16.447   39.381   \n",
       "2           2        15           437  1118846980400   16.426   43.381   \n",
       "3           2        16           437  1118846980500   16.405   47.380   \n",
       "4           2        17           437  1118846980600   16.385   51.381   \n",
       "\n",
       "      Global_X     Global_Y  v_length  v_Width    ...     D_Zone  Int_ID  \\\n",
       "0  6451137.641  1873344.962      14.5      4.9    ...        NaN     NaN   \n",
       "1  6451140.329  1873342.000      14.5      4.9    ...        NaN     NaN   \n",
       "2  6451143.018  1873339.038      14.5      4.9    ...        NaN     NaN   \n",
       "3  6451145.706  1873336.077      14.5      4.9    ...        NaN     NaN   \n",
       "4  6451148.395  1873333.115      14.5      4.9    ...        NaN     NaN   \n",
       "\n",
       "   Section_ID  Direction  Movement  Preceding  Following  Space_Headway  \\\n",
       "0         NaN        NaN       NaN          0          0            0.0   \n",
       "1         NaN        NaN       NaN          0          0            0.0   \n",
       "2         NaN        NaN       NaN          0          0            0.0   \n",
       "3         NaN        NaN       NaN          0          0            0.0   \n",
       "4         NaN        NaN       NaN          0          0            0.0   \n",
       "\n",
       "   Time_Headway  Location  \n",
       "0           0.0    us-101  \n",
       "1           0.0    us-101  \n",
       "2           0.0    us-101  \n",
       "3           0.0    us-101  \n",
       "4           0.0    us-101  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_raw = pd.read_csv(\"../Next_Generation_Simulation__NGSIM__\"\n",
    "                   \"Vehicle_Trajectories_and_Supporting_Data.csv\")\n",
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train and validate our model in later sections, we begin by splitting the dataset to test and train sets. Accordingly, in the next cell, perform the following tasks:\n",
    "\n",
    "1. Filter from the dataset all datapoints that are not from the US-101. This can be done by looking at the \"Location\" variable.\n",
    "2. Collect the speed, gap (space headway - lead vehicle length), lead speed, and acceleration (action) for each vehicle at every time step. If a vehicle has no leader or it's headway is zero, remove it from the dataset.\n",
    "3. Place 80% of them in a train set and 20% in a test set. Justify, in writing, how you chose to split the data.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "- Locating the speeds of the lead vehicles will be computationally demanding if you are doing so by searching a large list. Instead, consider reading the speeds of vehicle from a generated dictionary with keys corresponding to the time and vehicle ID, and/or using a divide and conquer approach where the data is separated by unique time stamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.062644073051672\n"
     ]
    }
   ],
   "source": [
    "# Filtering\n",
    "data = data_raw\n",
    "data = data[data.Location == 'us-101']\n",
    "data = data[['Vehicle_ID', 'Global_Time', 'v_length', 'v_Vel', 'v_Acc', 'Preceding', 'Space_Headway']]\n",
    "cnt0 = len(data)*len(data.columns.values)\n",
    "# print(len(data.groupby('Global_Time')))\n",
    "# print(len(data.groupby('Vehicle_ID')))\n",
    "leader_v_length, leader_v_Vel = range(2)\n",
    "leader_data = {vID: d[['Global_Time', 'v_length', 'v_Vel']].set_index('Global_Time')\n",
    "               for vID,d in data.groupby('Vehicle_ID')}\n",
    "leader_data = {vID: d[~d.index.duplicated()] for vID,d in leader_data.items()}\n",
    "data = data[['Vehicle_ID', 'Global_Time', 'v_Vel', 'Preceding', 'Space_Headway', 'v_Acc']]\n",
    "data = data[(data.Preceding != 0) & (data.Space_Headway != 0)]\n",
    "cnt1 = len(data)*len(data.columns.values)\n",
    "cnt2 = sum([len(d)*len(d.columns.values) for d in leader_data.values()])\n",
    "print((cnt1+cnt2)/cnt0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               v_length  v_Vel\n",
      "Global_Time                   \n",
      "1118847869000      47.0  19.89\n",
      "1118847869100      47.0  19.89\n",
      "1118847869200      47.0  19.89\n",
      "[47.   19.89]\n",
      "      Vehicle_ID    Global_Time  v_Vel  Preceding  Space_Headway  v_Acc\n",
      "1240           6  1118846993000  45.15          4          56.99    0.0\n",
      "1241           6  1118846993100  45.15          4          56.94    0.0\n",
      "1242           6  1118846993200  45.15          4          56.83    0.0\n",
      "[[6.00000000e+00 1.11884699e+12 4.51500000e+01 4.00000000e+00\n",
      "  5.69900000e+01 0.00000000e+00]\n",
      " [6.00000000e+00 1.11884699e+12 4.51500000e+01 4.00000000e+00\n",
      "  5.69400000e+01 0.00000000e+00]\n",
      " [6.00000000e+00 1.11884699e+12 4.51500000e+01 4.00000000e+00\n",
      "  5.68300000e+01 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(leader_data[1].iloc[:3])\n",
    "print(leader_data[1].iloc[0].values)\n",
    "print(data.iloc[:3])\n",
    "print(data.values[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27528792\n",
      "245.03268432617188 MB\n",
      "2260.3085327148438 MB\n",
      "(4588132, 6)\n",
      "(11850526, 25)\n"
     ]
    }
   ],
   "source": [
    "print(cnt1)\n",
    "print(sum(data.memory_usage())/1024**2, 'MB')\n",
    "print(sum(data_raw.memory_usage())/1024**2, 'MB')\n",
    "print(data.shape)\n",
    "print(data_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vehicle_ID, Global_Time,  v_Vel,  Preceding,  Space_Headway, v_Acc = range(len(data.columns.values))\n",
    "def get_leader(row): # expect ndarray\n",
    "    return leader_data[row[Preceding]].loc[row[Global_Time]].values\n",
    "\n",
    "leader_data_file = 'leader_data.npy'\n",
    "try:\n",
    "    leader_data = np.load(leader_data_file)\n",
    "except IOError:\n",
    "    leader_data = np.apply_along_axis(get_leader, 1, data.values)\n",
    "    np.save(leader_data_file, leader_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4588132, 2)\n"
     ]
    }
   ],
   "source": [
    "print(leader_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Vehicle_ID  v_Vel    Gap  leader_v_Vel  v_Acc\n",
      "1240           6  45.15  40.99         44.56    0.0\n",
      "1241           6  45.15  40.94         44.17    0.0\n",
      "1242           6  45.15  40.83         43.54    0.0\n",
      "1243           6  45.15  40.64         42.77    0.0\n",
      "1244           6  45.15  40.36         41.88    0.0\n",
      "(4588132, 5)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(columns=['Global_Time', 'Preceding'])\n",
    "# [Vehicle_ID, v_Vel, Space_Headway, v_Acc]\n",
    "data['Space_Headway'] -= leader_data[:,leader_v_length]\n",
    "data.rename(columns={'Space_Headway': 'Gap'}, inplace=True)\n",
    "# [Vehicle_ID, v_Vel, Gap, v_Acc]\n",
    "data['leader_v_Vel'] = leader_data[:,leader_v_Vel]\n",
    "# [Vehicle_ID, v_Vel, Gap, v_Acc, leader_v_Vel]\n",
    "NNoutput = data['v_Acc']\n",
    "data = data.drop(labels=['v_Acc'], axis=1)\n",
    "data = pd.concat([data, NNoutput], axis=1)\n",
    "# [Vehicle_ID, v_Vel, Gap, leader_v_Vel, v_Acc]\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2844\n"
     ]
    }
   ],
   "source": [
    "print(data.Vehicle_ID.nunique())\n",
    "data_dict = {k: v.drop(columns=['Vehicle_ID']) for k, v in data.groupby('Vehicle_ID')}\n",
    "data_all = pd.concat([v for v in data_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4588132\n",
      "(4588132, 4)\n"
     ]
    }
   ],
   "source": [
    "# vIDs = list(set(data_dict.keys()))\n",
    "# trainIDs = set(np.random.choice(vIDs, size=int(0.8*len(vIDs)), replace=False))\n",
    "# testIDs = {vID for vID in vIDs if vID not in trainIDs}\n",
    "N = len(data_all)\n",
    "print(N)\n",
    "print(data_all.values.shape)\n",
    "trainIdx = np.zeros(N, dtype=bool)\n",
    "trainIdx[np.random.choice(N, size=int(0.8*N), replace=False)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43.05 16.94 39.5   0.09]\n",
      " [42.98 16.56 39.49 -1.11]\n",
      " [42.73 16.21 39.55 -3.56]\n",
      " [42.26 15.9  39.56 -6.12]\n",
      " [41.61 15.65 39.51 -7.22]\n",
      " [40.97 15.48 39.45 -6.07]\n",
      " [40.49 15.37 39.42 -3.54]\n",
      " [40.25 15.31 39.33 -1.14]\n",
      " [38.49 15.26 36.   -0.42]\n",
      " [38.47 15.   35.6   0.2 ]]\n",
      "(3670505, 4) (917627, 4)\n",
      "0.7999998692278252\n"
     ]
    }
   ],
   "source": [
    "# 80 % of the data for training your model\n",
    "# train_set = pd.concat([data_dict[vID] for vID in trainIDs])\n",
    "train_set = data_all.values[trainIdx,:]\n",
    "\n",
    "# 20 % of the data for validation of your model\n",
    "# test_set = pd.concat([data_dict[vID] for vID in testIDs])\n",
    "test_set = data_all.values[~trainIdx,:]\n",
    "\n",
    "# print(len(vIDs), len(trainIDs), len(test_set))\n",
    "# print(train_set.head())\n",
    "print(train_set[:10,:])\n",
    "print(train_set.shape, test_set.shape)\n",
    "train_size = train_set.shape[0]\n",
    "test_size = test_set.shape[0]\n",
    "print(train_size/(train_size+test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f, test_f = \"train_set.npy\", \"test_set.npy\"\n",
    "np.save(train_f, train_set)\n",
    "np.save(test_f, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Fully-connected neural networks\n",
    "\n",
    "In order to estimate an appropriate acceleration model, we will perform regression on a deep fully-connected network using the NGSIM dataset presented in section a. As discussed in lecture 4a, this involves 1) running a **forward pass** through the neural network for a given input, 2) computing the **loss**, 3) **backpropagating** the loss through the neural network to compute the gradients, and finally 4) **updating** the weights and biases.\n",
    "\n",
    "We begin by implementing the forward pass. In the below method called `forward_pass`, we consider a neural network with *ReLU nonlinearities* applied to the hidden layers and *no nonlinearity* applied to the output layer. Fill in this method to get your forward pass running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3670505)\n",
      "[[43.05 42.98 42.73 42.26 41.61 40.97 40.49 40.25 38.49 38.47]\n",
      " [16.94 16.56 16.21 15.9  15.65 15.48 15.37 15.31 15.26 15.  ]\n",
      " [39.5  39.49 39.55 39.56 39.51 39.45 39.42 39.33 36.   35.6 ]\n",
      " [ 0.09 -1.11 -3.56 -6.12 -7.22 -6.07 -3.54 -1.14 -0.42  0.2 ]]\n",
      "[[ 0.96082127  0.95577316  0.93774421  0.90384977  0.85697448  0.81082035]\n",
      " [-0.97783336 -0.98753108 -0.9964632  -1.0043745  -1.01075458 -1.01509303]\n",
      " [ 0.65986228  0.65915613  0.66339301  0.66409915  0.66056842  0.65633155]\n",
      " [-0.01217265 -0.27605594 -0.81481764 -1.37776864 -1.61966165 -1.3667735 ]]\n",
      "[-0.01217265 -0.27605594 -0.81481764 -1.37776864 -1.61966165 -1.3667735\n",
      " -0.81041958 -0.28265302 -0.12432305  0.01201665  0.0164147  -0.48056548\n",
      " -1.09409411 -1.1336766  -1.51850639 -1.67903539 -0.86099721  0.26270577\n",
      "  0.83885093  0.39464741]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "train_f, test_f = \"train_set.npy\", \"test_set.npy\"\n",
    "train_set = np.load(train_f).T\n",
    "test_set = np.load(test_f).T\n",
    "print(train_set.shape)\n",
    "print(train_set[:,:10])\n",
    "data_mean = train_set.mean(axis=1, keepdims=True)\n",
    "data_var = train_set.std(axis=1, keepdims=True)\n",
    "train_set = (train_set - data_mean)/data_var\n",
    "test_set = (test_set - data_mean)/data_var\n",
    "train_inputs = train_set[:3,:]\n",
    "train_outputs = train_set[3:,:]\n",
    "test_inputs = test_set[:3,:]\n",
    "test_outputs = test_set[3:,:]\n",
    "print(train_set[:,:6])\n",
    "print(train_set[3,:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, W, b):\n",
    "    \"\"\"Performs a forward pass on a deep fully-connected network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        x : np.ndarray\n",
    "            datapoints from a minibatch of N samples of shape (N,D)\n",
    "        W : list of np.ndarray\n",
    "            weight matrices applied to each layer\n",
    "        b : list of np.ndarray\n",
    "            bias vectors applied to each layer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        np.ndarray\n",
    "            output from the neural network with shape (N, A)\n",
    "        list of list of np.ndarray\n",
    "            per sample, per layer pre-nonlinearity activation of\n",
    "            the hidden layers for each sample in the minibatch.\n",
    "            The first layer should be the input features\n",
    "    \"\"\"\n",
    "    ######################################\n",
    "    ##### implement your method here #####\n",
    "    ######################################\n",
    "    z = [x]\n",
    "    zi = x\n",
    "    for i, (Wi, bi) in enumerate(zip(W, b)):\n",
    "#         print(zi.shape, Wi.shape, (zi@Wi.T).shape, bi.shape)\n",
    "        zi = Wi@zi + bi[:,np.newaxis]\n",
    "        if i != (len(W)-1):\n",
    "            z.append(zi)\n",
    "            zi = ReLU(zi)\n",
    "    return zi, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we implement a backwards pass to compute the gradient of the loss with respect to the different hidden and input nodes. This involves computing the derivative of loss with respect to the nodes of the output layers, then incrementally moving through the hidden layers and computing their gradients as well. As you had done for the forward pass, fill in the method for the backwards pass to get it running as well. Assume a mean square error loss:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{L}(o,t) = \\frac{1}{2N} \\big|\\big|\\ o - t \\ \\big|\\big|^2\n",
    "\\end{equation}\n",
    "\n",
    "where $o$ is the output from the model, $t$ is the target value, and $N$ is the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, target):\n",
    "    return 1/(2*output.shape[1]) * np.linalg.norm(output-target)**2\n",
    "\n",
    "def loss_gradient(output, target):\n",
    "    return 1/output.shape[1] * (output - target)\n",
    "\n",
    "def ReLU_gradient(z):\n",
    "    return z > 0\n",
    "\n",
    "def backward_pass(s, output, target, z, W, b):\n",
    "    \"\"\"Performs a backwards pass on a deep fully-connected network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        output : np.ndarray\n",
    "            per sample prediction of the model with shape (N,A)\n",
    "        target : np.ndarray\n",
    "            per sample actual/target values for each sample with \n",
    "            shape (N,D)\n",
    "        z : list of list of np.ndarray\n",
    "            per sample, per layer pre-nonlinearity activation of\n",
    "            the hidden layers for each sample in the minibatch.\n",
    "            The first layer is the input features\n",
    "        W : list of np.ndarray\n",
    "            weight matrices applied to each layer\n",
    "        b : list of np.ndarray\n",
    "            bias vectors applied to each layer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list of np.ndarray\n",
    "            gradients for the weights each hidden layer\n",
    "        list of np.ndarray\n",
    "            gradients for the biases each hidden layer\n",
    "    \"\"\"\n",
    "    ######################################\n",
    "    ##### implement your method here #####\n",
    "    ######################################\n",
    "    L = len(W)\n",
    "    N = output.shape[1]\n",
    "    deltas = [None]*L\n",
    "    deltas[-1] = loss_gradient(output, target)\n",
    "#     print(output.shape, target.shape, deltas[-1].shape)\n",
    "    for i in range(L-2, -1, -1):\n",
    "#         print(W[i+1].T.shape, deltas[i+1].shape, ReLU_gradient(z[i+1]).shape)\n",
    "        deltas[i] = (W[i+1].T@deltas[i+1])*ReLU_gradient(z[i+1])\n",
    "    dW = [None]*L\n",
    "    db = [None]*L\n",
    "    for i in range(L):\n",
    "        db[i] = 1/N*np.sum(deltas[i], axis=1)\n",
    "#         dW[i] = 1/N*np.einsum('jN,Nk->jk', deltas[i], ReLU(z[i]))\n",
    "        dW[i] = 1/N*np.dot(deltas[i], ReLU(z[i]).T)\n",
    "#         tmp = 1/N*np.sum([np.outer(deltas[i][:,n], ReLU(z[i][:,n]))\n",
    "#                       for n in range(N)],\n",
    "#                      axis=0)\n",
    "#         print(np.linalg.norm(dW[i]-tmp))\n",
    "    W = [Wi - s*np.clip(dWi, -0.1, .1) for (Wi, dWi) in zip(W, dW)]\n",
    "    b = [bi - s*np.clip(dbi, -1, 1) for (bi, dbi) in zip(b, db)]\n",
    "    return W, b, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to train the parameters of a neural network to approximate the car-following behavior of people within the NGSIM dataset. In the below cell, perform the following tasks:\n",
    "\n",
    "1. Initialize the weights of deep neural network of hidden shape [32, 32] with 3 inputs and 1 output, with random uniform numbers between 0 and 1. Also, initialize the biases as all zeros.\n",
    "2. Using the `forward_pass` and `backward_pass` methods we created earlier in this problem, perform an SGD step to optimize the parameters of your neural network for the loss function described previously in this section. You may use the learning rate and batch size of your choosing. Continue to do so for 200 iterations.\n",
    "3. Once training is complete, plot the learning curve of your algorithm, i.e. the loss on the test set vs. the SGD step count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10000\n",
    "inputs0 = (np.random.rand(3, samples)-0.5)\n",
    "target0 = np.sum(inputs0, axis=0, keepdims=True)**2\n",
    "inputs0 = (inputs0 - np.mean(inputs0, axis=1, keepdims=True))/np.var(inputs0, axis=1, keepdims=True)\n",
    "target0 = (target0 - np.mean(target0))/np.var(target0)\n",
    "train_inputs = inputs0[:,:8000]\n",
    "train_outputs = target0[:,:8000]\n",
    "train_set = np.vstack((train_inputs, train_outputs))\n",
    "test_inputs = inputs0[:,8000:]\n",
    "test_outputs = outputs0[:,8000:]\n",
    "test_set = np.vstack((test_inputs, test_outputs))\n",
    "\n",
    "##########################################\n",
    "################# Step 1 #################\n",
    "##########################################\n",
    "nw = [3, 16, 32, 1]\n",
    "W0 = [np.random.rand(nw[i], nw[i-1]) for i in range(1, len(nw))]\n",
    "b0 = [0.1*np.ones(nw[i]) for i in range(1, len(nw))]\n",
    "# W0 = [1.0/3.0*np.ones((3,3)), 1.0/3.0*np.ones((1, 3))]\n",
    "# W0 = [np.array([[0,0,0],[0,0,0],[1,1,1]]), np.array([[0,0,1]])]\n",
    "# b0 = [np.array([0,0,100]), np.array([-90])]\n",
    "# print(W0)\n",
    "# print(b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = W0\n",
    "b = b0\n",
    "\n",
    "plt.figure()\n",
    "output, _ = forward_pass(inputs0, W, b)\n",
    "plt.scatter(target0, output)\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Output')\n",
    "plt.title('Initial output with random weights')\n",
    "\n",
    "##########################################\n",
    "################# Step 2 #################\n",
    "##########################################\n",
    "\n",
    "def loss_helper(data, W, b):\n",
    "    input = data[:3,:]\n",
    "    target = data[3:,:]\n",
    "    output, _ = forward_pass(input, W, b)\n",
    "    return loss(output, target)\n",
    "\n",
    "batch_size = 100\n",
    "s = 1\n",
    "iters = 100000\n",
    "labels = ['Pre-training', 'Post-training', 'Test']\n",
    "losses = np.zeros((iters, 3))\n",
    "Warr = [None]*iters\n",
    "barr = [None]*iters\n",
    "grads = np.zeros((iters, 2))\n",
    "for i in range(iters):\n",
    "    Warr[i] = W\n",
    "    barr[i] = b\n",
    "    idx = np.random.choice(train_set.shape[1], size=batch_size)\n",
    "    a1 = train_set[:3,idx]\n",
    "    target = train_set[3:,idx]    \n",
    "    output, z = forward_pass(a1, W, b)\n",
    "    if np.any(np.isinf(output)) or np.any(np.isnan(output)):\n",
    "        print('Infinite values in iteration {}'.format(i))\n",
    "        break\n",
    "    losses[i,0] = loss(output, target)\n",
    "    W, b, dW, db = backward_pass(s, output, target, z, W, b)\n",
    "    grads[i,:] = [np.linalg.norm(list(map(np.linalg.norm, dW))), np.linalg.norm(list(map(np.linalg.norm, db)))]\n",
    "    losses[i,1] = loss_helper(train_set[:,idx], W, b)\n",
    "    \n",
    "    idx = np.random.choice(test_set.shape[1], size=batch_size*10)\n",
    "    losses[i,2] = loss_helper(test_set[:,idx], W, b)\n",
    "losses = losses[:i,:]\n",
    "grads = grads[:i,:]\n",
    "\n",
    "##########################################\n",
    "################# Step 3 #################\n",
    "##########################################\n",
    "if not np.any(np.isinf(losses)):\n",
    "    plt.figure()\n",
    "    plt.plot(losses)\n",
    "    plt.ylim(0, np.mean(losses))\n",
    "    plt.legend(labels);\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    a1 = test_set[:3,:]\n",
    "    target = test_set[3:,:]\n",
    "    output, _ = forward_pass(a1, W, b)\n",
    "    plt.scatter(target, output)\n",
    "    x_eq_y = [np.min(target), np.max(target)]\n",
    "    plt.plot(x_eq_y, x_eq_y, ':')\n",
    "    plt.xlabel('Target')\n",
    "    plt.ylabel('Output')\n",
    "    plt.title('Final output')\n",
    "    plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(grads)\n",
    "plt.legend(['Weights', 'Biases'])\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "# print(W[0], W[1])\n",
    "# print(b[0], b[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0, 1):\n",
    "    print(Warr[j+i])\n",
    "\n",
    "for j in range(0, 1):\n",
    "    print(barr[j+i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(W[0], axis=0, keepdims=True))\n",
    "print(np.sum(W[0], axis=1, keepdims=True))\n",
    "\n",
    "print(W[0], W[1])\n",
    "print(b[0], b[1])\n",
    "W[0].dot(np.array([1,2,3]).T)\n",
    "W[1].dot(W[0].dot(np.array([1,2,3]).T)+b[0]) + b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(32, 3), (32, 32), (1, 32)]\n",
      "[(32,), (32,), (1,)]\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "################# Step 1 #################\n",
    "##########################################\n",
    "nw = [3, 32, 32, 1]\n",
    "W0 = [np.random.rand(nw[i], nw[i-1]) for i in range(1, len(nw))]\n",
    "b0 = [1*np.ones(nw[i]) for i in range(1, len(nw))]\n",
    "b0[-1] *= -1\n",
    "print([Wi.shape for Wi in W0])\n",
    "print([bi.shape for bi in b0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 3)\n",
      "[[ 0.48501314  0.75148389  0.70879201]\n",
      " [ 0.28291951  0.52771512 -0.10125889]\n",
      " [ 0.21794299  0.62123329  0.11423118]\n",
      " [ 0.72024226  0.35649952  0.4640469 ]\n",
      " [ 0.42008592  0.79922812 -0.01162998]\n",
      " [ 0.11178897  0.73128066  0.40234811]\n",
      " [ 0.8137462   0.59494002  0.33267056]\n",
      " [ 0.44609791 -0.07255887  0.53703526]\n",
      " [-0.02224546  0.30274239 -0.09436082]\n",
      " [ 0.15342372  0.09044591  0.42429155]\n",
      " [-0.11096664  0.13253923  0.86255865]\n",
      " [ 0.08181765  0.20510727  0.32906309]\n",
      " [ 0.72249834  0.51283061  0.28223808]\n",
      " [ 0.81978092  0.44958676  0.03571663]\n",
      " [ 0.41820827  0.67410815  0.78911076]\n",
      " [ 0.65170412  0.52762296 -0.02343058]\n",
      " [ 0.77024554  0.85353426  0.79655769]\n",
      " [ 0.55833769 -0.00664868 -0.06656524]\n",
      " [ 0.75932284  0.14861903  0.25393752]\n",
      " [ 0.00475102  0.30040374  0.42603937]\n",
      " [ 0.72756563  0.84467176 -0.05568876]\n",
      " [ 0.82997555  0.44333617  0.21826398]\n",
      " [-0.11484944  0.63254902  0.26910709]\n",
      " [-0.06247754 -0.0729904   0.06876072]\n",
      " [-0.06377025  0.32315148  0.41037291]\n",
      " [ 0.43385319  0.18856683  0.77405394]\n",
      " [ 0.61190452  0.67967648  0.01500371]\n",
      " [ 0.5350798   0.72499431  0.82332787]\n",
      " [ 0.30179052  0.55751441  0.33338401]\n",
      " [-0.02985002  0.58020949  0.33827294]\n",
      " [ 0.25588436  0.58327661  0.28487484]\n",
      " [ 0.08951977  0.16714204  0.16164332]]\n",
      "(32, 32)\n",
      "[[ 0.70655733  0.84001812  0.66122483 ...  0.45186418  0.42746715\n",
      "   0.50694705]\n",
      " [ 0.88767421  0.40658082  0.70451943 ...  0.02248202  0.14298617\n",
      "   0.11590934]\n",
      " [ 0.87384787  0.49573992  0.50733709 ...  0.12967787  0.8920302\n",
      "   0.39451954]\n",
      " ...\n",
      " [ 0.04916627  0.65694077  0.49497175 ...  0.78901017  0.26583947\n",
      "  -0.07923933]\n",
      " [ 0.29072326  0.52056071  0.61474551 ...  0.05141776  0.80347037\n",
      "   0.05996891]\n",
      " [ 0.04482499  0.23448253  0.64939925 ...  0.66252748  0.17185709\n",
      "   0.64001204]]\n",
      "(1, 32)\n",
      "[[ 0.50287755  0.85791146  0.05530953  0.4387453   0.60233431  0.73833266\n",
      "   0.11083389 -0.07898717  0.05854301  0.45463485  0.80138431  0.53599002\n",
      "   0.11463597  0.85203954  0.28822159  0.26692265 -0.04489375  0.58059232\n",
      "   0.77344434  0.38165376  0.22134462  0.23049707  0.3270018   0.20729864\n",
      "  -0.05000888 -0.08226218  0.47173549  0.65428943 -0.04634332  0.53981757\n",
      "   0.2283075   0.31271161]]\n",
      "(32,)\n",
      "[-0.41626917 -0.21506327 -0.2599209  -0.32847405 -0.28149011 -0.30244835\n",
      " -0.35869232 -0.21771723 -0.09973182 -0.1607188  -0.21081163 -0.15270908\n",
      " -0.32606693 -0.26810236 -0.35973936 -0.26036691 -0.36321397 -0.12644712\n",
      " -0.25082378 -0.19424037 -0.30740662 -0.31054941 -0.23715862 -0.06510657\n",
      " -0.17563794 -0.29019326 -0.29116964 -0.43512467 -0.28075767 -0.24411573\n",
      " -0.26849742 -0.10427595]\n",
      "(32,)\n",
      "[ 0.21413555 -0.08291309  0.72505973  0.25526755  0.16304526  0.10474762\n",
      "  0.61036267  0.96000622  0.70809486  0.24618931  0.07198092  0.20724639\n",
      "  0.61157068 -0.05970784  0.31955063  0.33273382  0.90187496  0.18103792\n",
      "  0.10007149  0.27455799  0.39085065  0.38468863  0.30258066  0.42417854\n",
      "  0.89122035  0.96933432  0.23871847  0.14298947  0.93315304  0.20446356\n",
      "  0.41193117  0.31230133]\n",
      "(1,)\n",
      "[-1.94917891]\n",
      "(3, 100)\n",
      "[[ 1.05733576e-03 -5.23017681e-02  5.34283081e-02  4.86436711e-02\n",
      "   8.14080331e-02 -1.54599387e-01 -2.48941192e-02 -2.84305901e-02\n",
      "   1.57806204e-01  8.38003516e-02  3.81382725e-02  5.04119065e-02\n",
      "   2.69047769e-02  6.92904198e-02  5.94091043e-02  5.33763012e-02\n",
      "   2.94531162e-02  4.27148818e-02  5.21801419e-02  3.36656770e-02\n",
      "  -1.19910769e-01  2.02478907e-02  3.83983071e-02 -1.05922152e-02\n",
      "   1.74915237e-02  6.40377205e-02  3.30936009e-02  2.71648115e-02\n",
      "   1.36937731e-03 -2.45820777e-02 -1.02644470e-01 -5.52661628e-02\n",
      "   4.54712487e-02  2.74248462e-02 -4.19536354e-03 -1.28285129e-02\n",
      "   9.58647127e-03 -1.12369765e-01  2.74248462e-02  8.42164070e-02\n",
      "   2.19121122e-02 -1.58969214e-02  2.41484100e-02 -1.95894130e-02\n",
      "  -3.20723199e-03 -1.35356825e-01 -7.65369946e-02  5.94598661e-03\n",
      "   9.19654386e-02  2.75288600e-02  1.65555236e-01 -1.09562636e-02\n",
      "  -6.40033260e-02  5.34283081e-02 -4.99614565e-02  1.05539246e-01\n",
      "   5.33763012e-02  3.34564041e-03 -2.24497938e-02 -9.45833972e-02\n",
      "   5.28562319e-02 -1.44198003e-01 -3.61796217e-02  2.74248462e-02\n",
      "  -2.45820777e-02  5.34283081e-02 -1.03112533e-01  1.05591253e-01\n",
      "   6.58059559e-02 -2.57782369e-02  2.03519045e-02 -1.39985442e-01\n",
      "   7.94317700e-02  5.34283081e-02  8.60886562e-02  5.34283081e-02\n",
      "   7.94317700e-02 -1.85505197e-03 -4.90773388e-02  1.05733576e-03\n",
      "   4.59393110e-02 -6.79038453e-02  1.09906582e-02 -5.54878875e-04\n",
      "  -1.12109731e-01 -1.19182672e-01 -7.65890015e-02  1.05435232e-01\n",
      "  -1.27244991e-02 -1.59489283e-02  7.71434653e-02  3.70968888e-03\n",
      "   5.34283081e-02 -2.45300708e-02  1.42138423e-03  2.74248462e-02\n",
      "   1.24001704e-01 -1.49814750e-01  3.13773724e-02 -1.03841875e-02]\n",
      " [ 2.26349057e-02 -2.54105227e-02  5.39162114e-02  1.02409176e-02\n",
      "  -1.23978121e-02 -2.19977798e-02 -1.68982040e-02 -2.09231565e-02\n",
      "   4.30462345e-02 -1.05025675e-02  4.67390307e-02  1.06577412e-02\n",
      "  -4.11344381e-03  8.11986161e-02 -3.55333715e-03 -8.07978052e-03\n",
      "   5.11221910e-02 -1.51853197e-02  2.64514464e-02  4.16524807e-02\n",
      "  -3.05947657e-02 -1.22154518e-02 -2.55035546e-03 -3.68359452e-03\n",
      "  -1.33486909e-02  2.46734334e-02  1.42788958e-02 -2.14655763e-03\n",
      "  -7.19403045e-03 -1.63055330e-02 -2.01546381e-02 -1.34138195e-02\n",
      "   2.08503798e-02  6.08570771e-03 -8.15142207e-03 -1.44037755e-02\n",
      "   2.52316883e-03 -2.29942486e-02  3.75558866e-02  7.55761592e-03\n",
      "   2.07982769e-02  5.08272602e-03  4.63743101e-02  2.68599054e-03\n",
      "  -9.21953244e-03 -1.98224818e-02 -2.47983131e-02 -5.22714427e-03\n",
      "   2.74739667e-02 -6.13894581e-03  3.55220200e-03 -4.52375451e-03\n",
      "   3.26321583e-02  2.80731506e-02  2.58522626e-02  3.29820014e-03\n",
      "  -1.51918325e-02 -7.46105804e-03  1.52484826e-04 -1.40260291e-02\n",
      "   1.02409176e-02 -2.98653245e-02 -1.17595510e-02  3.64552119e-02\n",
      "  -2.06300774e-02  2.96622904e-02 -2.32612762e-02  2.78368356e-03\n",
      "  -6.36689619e-03 -1.53937315e-02 -5.11827725e-04 -2.94615267e-02\n",
      "  -1.15250878e-02  1.52484826e-04  4.41859864e-02  1.43440245e-02\n",
      "   4.56169657e-03  6.45042833e-03 -1.00466667e-02 -1.26713526e-02\n",
      "   1.48976183e-02  7.45155828e-04 -8.02767757e-03 -9.21301958e-03\n",
      "  -2.17372650e-02 -7.80624006e-03 -8.35983385e-03 -1.95228899e-02\n",
      "   1.27921102e-03 -2.40037432e-02  3.32313422e-02  1.47538691e-01\n",
      "  -3.29282243e-03 -2.46875943e-02  8.88624102e-03  5.25857346e-03\n",
      "   3.03768542e-03 -2.70908427e-02 -6.88141278e-03 -9.27163539e-03]\n",
      " [-1.06980594e-02 -5.60246124e-02  4.90891099e-02  7.40212073e-02\n",
      "   4.90891099e-02 -1.50367669e-01 -4.28604650e-02 -2.57071820e-02\n",
      "   1.57543733e-01  4.46511966e-02  5.15823197e-02  5.25297394e-02\n",
      "   2.41570126e-02  9.37674284e-02  2.54534817e-02  6.20039364e-02\n",
      "   4.90891099e-02  3.57255058e-02  3.66230613e-02  4.90392457e-02\n",
      "  -1.27330411e-01 -5.74706740e-02  2.41570126e-02 -1.99727997e-02\n",
      "  -8.70349166e-03  3.40301232e-02  2.41570126e-02  4.16147056e-03\n",
      "   9.54680358e-03 -2.58567746e-02 -1.00503474e-01 -6.42023403e-02\n",
      "   3.66230613e-02  2.39575558e-02 -4.76422028e-03  1.13917788e-02\n",
      "  -7.75084712e-04 -1.25435571e-01  3.43791725e-02  4.95877519e-02\n",
      "   2.41570126e-02 -2.81951669e-03  4.90891099e-02 -1.44877382e-02\n",
      "   1.89711364e-02 -9.21761535e-02 -7.40754509e-02  1.63283341e-02\n",
      "   6.86358742e-02  5.22305542e-02  1.48318857e-01 -4.96367706e-03\n",
      "  -5.29828965e-02  1.40844453e-02 -2.37624784e-02  9.05262557e-02\n",
      "   3.05894937e-02 -1.92196119e-03 -3.46827371e-02 -7.55713767e-02\n",
      "   7.70629231e-02 -1.29823620e-01 -3.81233665e-02  5.05351716e-02\n",
      "  -2.39120710e-02  3.79693945e-02 -1.50367669e-01  1.02792848e-01\n",
      "   4.90891099e-02 -2.57570462e-02 -7.20756582e-03 -1.41092928e-01\n",
      "   7.40212073e-02  4.90891099e-02  8.42433672e-02  6.07074673e-02\n",
      "   5.48733565e-02 -1.42384173e-02 -4.76972919e-02  1.55305069e-02\n",
      "   7.04808494e-02 -6.67952784e-02  1.97190993e-02 -2.57019572e-03\n",
      "  -7.88624135e-02 -3.81233665e-02 -1.34405902e-02  8.64872559e-02\n",
      "  -2.84497127e-02 -9.45145458e-03  5.55215911e-02  2.03174696e-02\n",
      "   3.85179007e-02 -5.75704024e-02  1.45332230e-02 -2.38622068e-02\n",
      "   1.19397624e-01 -1.25435571e-01  4.10111104e-02  1.16909640e-02]]\n",
      "(32, 100)\n",
      "[[-0.40632928 -0.50044161 -0.31504461 ... -0.59819736 -0.37715366\n",
      "  -0.41998666]\n",
      " [-0.20173607 -0.23759698 -0.17646566 ... -0.25904356 -0.21397016\n",
      "  -0.22407775]\n",
      " [-0.24685095 -0.29350532 -0.20917452 ... -0.32373036 -0.25267263\n",
      "  -0.26660843]\n",
      " ...\n",
      " [-0.23463317 -0.27624956 -0.19782235 ... -0.29779358 -0.23517206\n",
      "  -0.24523051]\n",
      " [-0.25807206 -0.31266199 -0.20939363 ... -0.35836756 -0.25279917\n",
      "  -0.27323203]\n",
      " [-0.10212733 -0.12226117 -0.08254647 ... -0.14249118 -0.09598806\n",
      "  -0.10486546]]\n",
      "(32, 100)\n",
      "[[ 0.21407305  0.21407305  0.21407305 ...  0.21407305  0.21407305\n",
      "   0.21407305]\n",
      " [-0.08291309 -0.08291309 -0.08291309 ... -0.08291309 -0.08291309\n",
      "  -0.08291309]\n",
      " [ 0.72505287  0.72505287  0.72505287 ...  0.72505287  0.72505287\n",
      "   0.72505287]\n",
      " ...\n",
      " [ 0.20439647  0.20439647  0.20439647 ...  0.20439647  0.20439647\n",
      "   0.20439647]\n",
      " [ 0.4119028   0.4119028   0.4119028  ...  0.4119028   0.4119028\n",
      "   0.4119028 ]\n",
      " [ 0.31226247  0.31226247  0.31226247 ...  0.31226247  0.31226247\n",
      "   0.31226247]]\n"
     ]
    }
   ],
   "source": [
    "W = W0\n",
    "b = b0\n",
    "##########################################\n",
    "################# Step 2 #################\n",
    "##########################################\n",
    "\n",
    "def loss_helper(data, W, b):\n",
    "    input = data[:3,:]\n",
    "    target = data[3:,:]\n",
    "    output, _ = forward_pass(input, W, b)\n",
    "    return loss(output, target)\n",
    "\n",
    "batch_size = 100\n",
    "s = 0.5\n",
    "iters = 10000\n",
    "labels = ['Pre-training', 'Post-training', 'Test']\n",
    "losses = np.zeros((iters, 3))\n",
    "grads = np.zeros((iters, 2))\n",
    "for i in range(iters):\n",
    "    idx = np.random.choice(train_set.shape[1], size=batch_size)\n",
    "    a1 = train_set[:3, idx]\n",
    "    target = train_set[3:, idx]\n",
    "    output, z = forward_pass(a1, W, b)\n",
    "    losses[i,0] = loss(output, target)\n",
    "    W, b, dW, db = backward_pass(s, output, target, z, W, b)\n",
    "    grads[i,:] = [np.linalg.norm(list(map(np.linalg.norm, dW))), np.linalg.norm(list(map(np.linalg.norm, db)))]\n",
    "    losses[i,1] = loss_helper(train_set[:,idx], W, b)\n",
    "    \n",
    "    idx = np.random.choice(test_set.shape[1], size=batch_size*10)\n",
    "    losses[i,2] = loss_helper(test_set[:,idx], W, b)\n",
    "\n",
    "for Wi in W:\n",
    "    print(Wi.shape)\n",
    "    print(Wi)\n",
    "for bi in b:\n",
    "    print(bi.shape)\n",
    "    print(bi)\n",
    "for zi in z:\n",
    "    print(zi.shape)\n",
    "    print(zi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.36246191e+04 5.45947963e+03 5.54533892e+03]\n",
      " [5.51541232e+03 2.06762017e+01 2.21089000e+01]\n",
      " [1.87741017e+01 1.03998764e+00 1.40349749e+00]\n",
      " [1.56879249e+00 1.16801532e+00 9.76395020e-01]\n",
      " [1.43044194e+00 1.12487086e+00 7.95445181e-01]\n",
      " [1.61694290e+00 1.28533241e+00 1.01550476e+00]\n",
      " [1.21245343e+00 1.03847791e+00 6.41970829e-01]\n",
      " [6.65408683e-01 6.23819575e-01 4.60071173e-01]\n",
      " [2.74948868e-01 2.55982578e-01 5.58770989e-01]\n",
      " [2.79063525e-01 2.59305183e-01 8.30997800e-01]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################\n",
    "################# Step 3 #################\n",
    "##########################################\n",
    "print(losses[:10,:])\n",
    "plt.plot(losses)\n",
    "plt.ylim(0, 2*np.median(losses))\n",
    "plt.legend(labels);\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# diff = losses[:,1]-losses[:,0]\n",
    "# plt.plot(diff)\n",
    "# plt.ylim(0, 2*np.median(diff))\n",
    "# plt.title('Improvement in loss of training minibatch');\n",
    "\n",
    "plt.figure()\n",
    "a1 = test_set[:3,:]\n",
    "target = test_set[3:,:]\n",
    "output, _ = forward_pass(a1, W, b)\n",
    "plt.scatter(target, output)\n",
    "x_eq_y = [np.min(target), np.max(target)]\n",
    "plt.plot(x_eq_y, x_eq_y, ':')\n",
    "# plt.ylim(np.min(output), np.max)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(grads)\n",
    "plt.legend(['Weights', 'Biases'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007020793480065901\n",
      "-0.5486297355733892\n"
     ]
    }
   ],
   "source": [
    "print(np.min(output))\n",
    "print(np.min(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Tensorflow\n",
    "\n",
    "While implementing regression alorithms in mathematical libraries such as `numpy` is great practice for learning how these algorithms work, in reality practitioners rarely do so and instead rely on machine learning libraries such as `tensorflow`. In the below cell, perform the following tasks:\n",
    "\n",
    "1. Implement the regression algorithm for the problem posed in this exercise using `tensorflow`. Maintain the same model parameters as those described in section b).\n",
    "2. Try adding a batch normalization$^1$ or dropout$^2$ layer and compare the training performance of the neural network model wit or without these tricks. What do your results tell you about the chosen modification to the neural network?\n",
    "\n",
    "**Hint**: some useful tensroflow classes and methods include: `tf.layers.dense`, `tensorflow.contrib.slim.fully_connected`, `tf.nn.relu`, `tf.nn.batch_normalization`, `tf.nn.dropout`\n",
    "\n",
    "$^1$ Ioffe, Sergey, and Christian Szegedy. \"Batch normalization: Accelerating deep network training by reducing internal covariate shift.\" arXiv preprint arXiv:1502.03167 (2015).\n",
    "\n",
    "$^2$ Srivastava, Nitish, et al. \"Dropout: a simple way to prevent neural networks from overfitting.\" The Journal of Machine Learning Research 15.1 (2014): 1929-1958."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,217\n",
      "Trainable params: 1,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(32,\n",
    "            activation=tf.nn.relu,\n",
    "            use_bias=True,\n",
    "            kernel_initializer=keras.initializers.RandomUniform(0, 1),\n",
    "            bias_initializer=keras.initializers.Zeros(),\n",
    "            input_shape=(train_inputs.shape[0],)),\n",
    "        keras.layers.Dense(32,\n",
    "            activation=tf.nn.relu,\n",
    "            use_bias=True,\n",
    "            kernel_initializer=keras.initializers.RandomUniform(0, 1),\n",
    "            bias_initializer=keras.initializers.Zeros()),\n",
    "        keras.layers.Dense(1,\n",
    "            use_bias=True,\n",
    "            kernel_initializer=keras.initializers.RandomUniform(0, 1),\n",
    "            bias_initializer=keras.initializers.Zeros())\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3670505 samples, validate on 917627 samples\n",
      "Epoch 1/3\n",
      " - 81s - loss: 44781.4222 - mean_absolute_error: 1.2800 - val_loss: 0.9974 - val_mean_absolute_error: 0.6276\n",
      "Epoch 2/3\n",
      " - 81s - loss: 1.0003 - mean_absolute_error: 0.6306 - val_loss: 0.9975 - val_mean_absolute_error: 0.6322\n",
      "Epoch 3/3\n",
      " - 82s - loss: 1.0003 - mean_absolute_error: 0.6305 - val_loss: 0.9975 - val_mean_absolute_error: 0.6253\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "########## train your model here using tensorflow ##########\n",
    "############################################################\n",
    "# Display training progress by printing a single dot for each completed epoch\n",
    "# class PrintDot(keras.callbacks.Callback):\n",
    "#     def on_epoch_end(self, epoch, logs):\n",
    "#         if epoch % 1 == 0:\n",
    "#             print('')\n",
    "#         print('.', end='')\n",
    "\n",
    "# Store training stats\n",
    "history = model.fit(train_inputs.T, train_outputs.T,\n",
    "                    batch_size=32, # default\n",
    "                    epochs=3,\n",
    "                    validation_data=(test_inputs.T, test_outputs.T),\n",
    "                    shuffle=True,\n",
    "                    verbose=2)\n",
    "#                     callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.7510222320485545,\n",
       " 2.687094432930752,\n",
       " -0.025712834336028105,\n",
       " 0.004640366546974105)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = model.predict(test_inputs.T).flatten()\n",
    "plt.figure()\n",
    "plt.scatter(test_outputs, test_predictions)\n",
    "plt.xlabel('True values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "###### train your model using a neural network trick #######\n",
    "############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Traffic Signal Timing with DQN\n",
    "\n",
    "In this problem, you will implement your first reinforcement learning algorithm: DQN. The algorithm will then be used to control traffic lights in a simple network. Specifically, we consider a single intersection as seen in the figure below, with lanes of length 300 m on either direction and vehicles entering the network from the north-south and east-west directions at a rate of 300 veh/hr and 100 veh/hr, respectively. We choose to study the problem of traffic light signal control using DQN because of the discretizable nature of the action space for the resulting MDP (see the [implementation of the environment](https://github.com/flow-project/flow/blob/master/flow/envs/green_wave_env.py) for more).\n",
    "\n",
    "<img src=\"img/dqn_network.png\" width=\"600\">\n",
    "\n",
    "Before we begin optimizing the performance of the traffic light in the given problem, let us first analyze the performance of the baseline form of this problem. Such baselines in Flow can be extracted by simulating the dynamical behavior the network in the absence of any reinforcement learning agent. In this case, we consider a baseline signal schedule where the portion of time when the light is equal for both directions. This control strategy is not optimal, and is symptomatic of one of the primary sources of traffic congestion today.\n",
    "\n",
    "The below cell instantiates the above described network and computes the average delay of vehicles in the system. Run it once and look at the average return that you get. Note that, while it is not necessary, if you interested in further understanding the inner working of the below lines of code, we recommend you review the following [tutorial on traffic lights](https://github.com/berkeleyflow/flow/blob/master/tutorials/tutorial08_traffic_lights.ipynb) in Flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "WARNING: Inflows will cause computational performance to\n",
      "significantly decrease after large number of rollouts. In \n",
      "order to avoid this, set SumoParams(restart_instance=True).\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "Round 0, return: -265.9383312068948\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "WARNING: Inflows will cause computational performance to\n",
      "significantly decrease after large number of rollouts. In \n",
      "order to avoid this, set SumoParams(restart_instance=True).\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "**********************************************************\n",
      "Round 1, return: -262.50088011116526\n",
      "Average, std return: -264.21960565903004, 1.7187255478647785\n",
      "Average, std speed: 11.880784504834846, 0.0214035455790218\n",
      "-----------------\n",
      "The total return across 2 runs is -264.220 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flow.envs import PO_TrafficLightGridEnv\n",
    "from flow.core.experiment import SumoExperiment\n",
    "from hw2_utils import create_scenario, env_params\n",
    "from hw2_utils import sumo_params_test as sumo_params\n",
    "\n",
    "scenario = create_scenario()\n",
    "env = PO_TrafficLightGridEnv(env_params, sumo_params, scenario)\n",
    "exp = SumoExperiment(env, scenario)\n",
    "\n",
    "num_runs = 2\n",
    "results = exp.run(num_runs, env_params.horizon)\n",
    "total_return = np.mean(results[\"returns\"])\n",
    "print(\"-----------------\")\n",
    "print('The total return across %d runs is %.3f seconds' %(num_runs, total_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Creating a neural network\n",
    "\n",
    "We now begin to design the various constituents of our algorithm. The algorithm we will create here, as well as most online RL algorithms in practice, consists of four primary components:\n",
    "\n",
    "- a **function approximator**, either for the policy or the value/Q function\n",
    "- a method for **computing actions**,\n",
    "- a **sample generator**,\n",
    "- and an **optimization scheme**.\n",
    "\n",
    "The function approximator is the part of the control strategy that is periodically trained by the RL algorithm. In the case of DQN, the policy denotes the RL agent's estimation of the Q function ($Q : S \\to \\mathbb{R}^A$), which computes the value of any given action $a_i \\in [0, A-1]$ from a starting state $s \\in S$.\n",
    "\n",
    "For this problem, let us consider a simple feed forward network of hidden shape *[100, 50, 25]* with a *ReLU* nonlinearity for the hidden layers, and a weighted sum of with *no nonlinearity* for the output layer. Moreover, let the initial values of all weights in the network to set to truncated normal values with standard a devaition of 1.0, and all biases be initially set to zero. In the below cell, implement this neural network and have the method return the tensorflow Variable corresponding to the output layer. Note that the scope of the output layer should match the one specified in the input parameters.\n",
    "\n",
    "**Hint**: some useful tensroflow classes and methods include: `tf.layers.dense`, `tensorflow.contrib.slim.fully_connected`, `tf.nn.relu`, `tf.truncated_normal_initializer`, `tf.zeros_initializer`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_shapes = [100, 50, 25]\n",
    "\n",
    "def fully_connected_network(inputs, num_actions, scope):\n",
    "    \"\"\"Creates a fully-connected neural network computation graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        inputs : tf.Placeholder\n",
    "            placeholders for the input features\n",
    "        num_actions : int\n",
    "            range of actions that can be performed by the policy. Actions \n",
    "            returned must be between 0 to num_actions, inclusive.\n",
    "        scope : str\n",
    "            a label that is used to call a specific component in the \n",
    "            computation graph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tf.Variable\n",
    "            the output player that is responsible for returning the neural\n",
    "            network estimation. The scope of the output layer should match \n",
    "            the one specified in the above parameters.\n",
    "    \"\"\"\n",
    "    ##############################################\n",
    "    ##### construct your neural network here #####\n",
    "    ##############################################\n",
    "    for shape in hidden_shapes:\n",
    "        inputs = layers.fully_connected(\n",
    "            inputs, shape,\n",
    "            activation_fn=tf.nn.relu,\n",
    "            weights_initializer=initializers.truncated_normal(0, 1),\n",
    "            biases_initializer=tf.zeros_initializer(),\n",
    "        )\n",
    "    \n",
    "    outputs = layers.fully_connected(\n",
    "        inputs, num_actions,\n",
    "        activation_fn=None,\n",
    "        weights_initializer=initializers.truncated_normal(0, 1),\n",
    "        biases_initializer=tf.zeros_initializer(),\n",
    "        scope=scope\n",
    "    )\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Computing actions\n",
    "\n",
    "Next, we impelment our method for computing actions. In DQN, the action taken by the RL agent is chosen to be the action which maximizes the Q value estimated by the policy in section a). Moreover, in order to promote exploration of the task space, the agent performs a random action with probability $\\epsilon$, where $\\epsilon$ is an exploration rate term that in practice starts high, and is periodically annealed to a smaller value. Mathematically, this is written as:\n",
    "\n",
    "\\begin{equation}\n",
    "a_t(s_t) = \n",
    "\\begin{cases}\n",
    "randint(0, A-1) && \\text{if }uniform(0,1) < \\epsilon \\\\\n",
    "\\underset{a}{\\arg\\max}(Q(s_t,a))  && \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "Fill in the below cell to compute and return appropriate actions for the given state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_action(sess, obs, obs_ph, num_actions, q_func, exploration_rate):\n",
    "    \"\"\"Computes an action from the RL policy given an observation.\n",
    "\n",
    "    With probability exploration_rate, the action is a random integer within \n",
    "    the range of the action space.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        sess : tf.session\n",
    "            The tensorflow session\n",
    "        obs : list\n",
    "            The observation\n",
    "        obs_ph : tf.placeholder\n",
    "            placeholder for the observation\n",
    "        num_actions : int\n",
    "            range of actions (the returned action must be an integer between\n",
    "            0 and num_actions-1, inclusive)\n",
    "        exploration_rate : float\n",
    "            Probability of selecting action other than the argmax of the \n",
    "            q function\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        int\n",
    "            action to take\n",
    "    \"\"\"\n",
    "    ##################################################\n",
    "    ##### implement your action computing method #####\n",
    "    ##################################################\n",
    "    if np.random.rand() < exploration_rate:\n",
    "        return np.random.randint(num_actions)\n",
    "    else:\n",
    "        return sess.run(q_func, feed_dict={obs_ph: obs})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Collecting samples from OpenAI gym environments\n",
    "\n",
    "All RL algorithms require data to train the parameters of their policies. This is generally done by allowing the policy to specify an action $a_t(s_t)$ and then having a simulation environment return an updated state $s_{t+1}$ as well as a reward value associated with the state/action paire $r_t(s_t,a_t)$. In the lectures, we discussed the library \"OpenAI gym\", which serves to standardize the process of collecting data across multiple RL algorithms. Gym environments do so by relying on two methods for updating the simulation:\n",
    "\n",
    "- **step**: Advances the simulation by one step. Takes as an input an action from the agent, and returns the next state, the reward, a boolean term to specify whether the rollout completed prematurely, and an additional (optional) info dict.\n",
    "- **reset**: Returns the environment to some initial state. Unlike the step method, it does not take as an input any action, and only returns the initial state of the environment.\n",
    "\n",
    "The below method is designed to collect a single rollout worth of simulation data from gym-compatible environments and return the samples as a list of dictionary elements. Fill in the missing elements of this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(env, sess, s_t_ph, q_func, exploration_policy):\n",
    "    \"\"\"Executes a single rollout of the environment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        env : gym.Env\n",
    "            OpenAI gym-compatible environment\n",
    "        sess : tf.Session\n",
    "            blank\n",
    "        s_t_ph : tf.Placeholder\n",
    "            placeholder for the input states\n",
    "        q_func : tf.Variable\n",
    "            output layer to the Q function, which returns expected values\n",
    "        exploration_policy : object\n",
    "            an object that provides appropriate exploration rates for the\n",
    "            action computing procedure\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list of dict\n",
    "            each element is a new sample, with each dict containing keys \n",
    "            for \"state\", \"action\", \"next_state\", \"reward\", and \"done_mask\"\n",
    "    \"\"\"\n",
    "    # the samples list will contain information from all new simulation steps\n",
    "    samples = []\n",
    "\n",
    "    # start a new rollout by resetting the environment and collecting the initial state\n",
    "    ### FILL IN ###\n",
    "    observation = env.reset()\n",
    "    num_actions = np.max(q_func.shape.as_list())\n",
    "    \n",
    "    for i in range(env.env_params.horizon):\n",
    "        # compute the action from the compute_action method from part b)\n",
    "        ### FILL IN ###\n",
    "        action = compute_action(sess, observation, s_t_ph, num_actions, q_func, exploration_policy)\n",
    "\n",
    "        # advance the environment once and collect the next state, reward, done, \n",
    "        # and info parameters from the environment\n",
    "        ### FILL IN ###\n",
    "        observation, reward, done, info = env.step(action)\n",
    "\n",
    "        # add to the samples list a dict containing: \"state\", \"action\", \"next_state\", \n",
    "        # \"reward\", and \"done_mask\"\n",
    "        samples.append({\"state\":       observation,\n",
    "                        \"action\":      action,\n",
    "                        \"next_state\":  observation,\n",
    "                        \"reward\":      reward,\n",
    "                        \"done_mask\":   done\n",
    "                       })\n",
    "\n",
    "        # if the environment returns a True for the done parameter, end the rollout \n",
    "        # before the time horizon is met\n",
    "        ### FILL IN ###\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Training\n",
    "\n",
    "In this section, we implement the core of our RL algorithm: the training operation. For the standard form of DQN, training occurs at the level of the Q function $Q(s,a)$ by optimizing over the loss:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{Q}(s_t,a_t) = \\big( R(s_t,a_t) + \\gamma \\cdot \\max_a Q_\\text{target}(s_{t+1},a) \\big) - Q(s_t,a_t)\n",
    "\\end{equation}\n",
    "\n",
    "where $\\gamma$ is a discount rate and $Q_\\text{target}$ is the Q target function that is stored separately from the Q value and updated less frequently in order to further stabilize the training procedure.\n",
    "\n",
    "The below cell is responsible for constructing the tensforflow placeholders and methods that will be called during the optimization scheme. Following the comments placed on each of the empty operations, and referring to the lecture on DQN, fill in the remainder of this cell.\n",
    "\n",
    "**Hint**: some useful tensroflow classes and methods include: `tf.placeholder`, `tf.one_hot`, `tf.losses.huber_loss`, `tf.train.AdamOptimizer`, `tf.clip_by_norm`, `tf.assign`, `tf.group`, `tf.global_variables_initializer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_update(env, gamma, learning_rate, norm_clipping):\n",
    "    \"\"\"Constructs the necessary tensforflow components needed to execute\n",
    "    the DQN optimization scheme.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        env : gym.Env\n",
    "            OpenAI gym-compatible environment\n",
    "        gamma : float\n",
    "            discount rate\n",
    "        learning_rate : float\n",
    "            used during the optimization step\n",
    "        norm_clipping : float\n",
    "            saturation point for the gradients\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        tf.Variable\n",
    "            output layer to the Q function\n",
    "        list of tf.Placeholder\n",
    "            several placeholders that we create to later feed data through\n",
    "        tf.Operation\n",
    "            method for updating the parameters of the Q function\n",
    "        tf.Operation\n",
    "            method for transferring the parameters of the Q function to the \n",
    "            Q target\n",
    "        tf.Session\n",
    "            tensorflow session\n",
    "    \"\"\"\n",
    "    # initialize a tensorflow session\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # number of discrete actions the agent can perform\n",
    "    num_actions = env.action_space.n\n",
    "    # number of elements in the observation space\n",
    "    obs_size = env.observation_space.shape[0]\n",
    "\n",
    "    # actions placeholder (use tf.int32 as the dtype)\n",
    "    a_t_ph =  ### FILL IN ###\n",
    "    # state placeholder (use tf.int32 as the dtype)\n",
    "    s_t_ph =  ### FILL IN ###\n",
    "    # next state placeholder (use tf.int32 as the dtype)\n",
    "    s_tp1_ph =  ### FILL IN ###\n",
    "    # reward placeholder (use tf.int32 as the dtype)\n",
    "    rew_ph =  ### FILL IN ###\n",
    "    # done placeholder (use tf.int32 as the dtype)\n",
    "    done_ph =  ### FILL IN ###\n",
    "\n",
    "    ph_list = s_t_ph, s_tp1_ph, a_t_ph, rew_ph, done_ph\n",
    "\n",
    "    # construct your q functions using the method from part a) and give it the scope \"q_func\"\n",
    "    q = ### FILL IN ###\n",
    "\n",
    "    # get the weights of your q function\n",
    "    q_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                 scope=tf.get_variable_scope().name + \"q_func\")\n",
    "\n",
    "    # construct the q target using the method from part a) and give it the scope \"q_target\"\n",
    "    q_target = ### FILL IN ###\n",
    "\n",
    "    # get the weights of your q function\n",
    "    q_target_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                                        scope=tf.get_variable_scope().name + \"q_target\")\n",
    "\n",
    "    # perform the update step here. Be sure to use \"gamma\" and \"learning_rate\"\n",
    "    # as specified by the input parameters, and clip the gradients by the \n",
    "    # \"norm_clipping\" term\n",
    "    update =  ### FILL IN ###\n",
    "\n",
    "    # create an assignment operator q_target_params to copy the q function params\n",
    "    # to the q_target params. \"update_target_expr\" will be called periodically to \n",
    "    # copy Q network to target Q network. You will want to use the variables q_params\n",
    "    # and q_target_params\n",
    "    update_target_expr =  ### FILL IN ###\n",
    "\n",
    "    # initialize all the variables\n",
    "    ### FILL IN ###\n",
    "\n",
    "    return q, ph_list, update, update_target_expr, sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next method is responsible for executing the entire training session. In this method, the replay buffer is periodically updated with data from the rollouts in part c) and a series of update steps are performed after every rollout. Note that this is somewhat different from the regular DQN approach, where the Q functions are trained after a number of steps instead of rollouts. Finally, after a number of rollouts, the parameters of the target Q function are modified to match those of the actual Q function.\n",
    "\n",
    "With the above description in mind, fill in the below cell to complete your DQN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def train(env,\n",
    "          num_iterations=20,\n",
    "          steps_per_iteration=10000,\n",
    "          num_opt_steps=10,\n",
    "          batch_size=1000,\n",
    "          learning_rate=1e-4,\n",
    "          buffer_size=50000,\n",
    "          initial_explore_rate=1.0,\n",
    "          final_explore_rate=0.02,\n",
    "          anneal_rate=int(1e5),\n",
    "          norm_clipping=10, \n",
    "          gamma=0.5):\n",
    "    \"\"\"Runs an entire training session of DQN on an environment.\n",
    "\n",
    "    Note that the hyper-parameters are inputs to this method in order to \n",
    "    facilitate hyper-parameter tuning.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        env : gym.Env\n",
    "            OpenAI gym-compatible environment\n",
    "        num_iterations : int\n",
    "            number of training iterations before training stops\n",
    "        steps_per_iteration : int\n",
    "            number of steps to perform before the parameters of the \n",
    "            Q target are updated\n",
    "        num_opt_steps : int\n",
    "            number of optimization steps to take after every rollout\n",
    "        learning_rate : float\n",
    "            used by the optimizer\n",
    "        buffer_size : int\n",
    "            maximum number of elements the replay buffer can hold\n",
    "        initial_explore_rate : float\n",
    "            used by the exploration strategy\n",
    "        final_explore_rate : float\n",
    "            used by the exploration strategy\n",
    "        anneal_rate : int\n",
    "            used by the exploration strategy\n",
    "        batch_size : int\n",
    "            number of samples used to compute the gradient\n",
    "        norm_clipping : float\n",
    "            saturation point for the gradients\n",
    "        gamma : float\n",
    "            discount rate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        list of float\n",
    "            a list of average returns per ten rollouts\n",
    "    \"\"\"\n",
    "    # define the replay buffer\n",
    "    replay_buffer =  ### FILL IN ###\n",
    "\n",
    "    # define the exploration policy (the y term corresponds to the number of previous steps)\n",
    "    exploration_policy_offset = lambda x,y: max(initial_explore_rate - 1/anneal_rate * (x+y), final_explore_rate)\n",
    "\n",
    "    # collect the necessary tensorflow-specific components\n",
    "    q_func, ph_list, update, update_target_expr, sess = construct_update(env, gamma, learning_rate, norm_clipping)\n",
    "    s_t_ph, s_tp1_ph, a_t_ph, rew_ph, done_ph = ph_list\n",
    "\n",
    "    # to store cumulative returns per rollout\n",
    "    cumulative_return_per_rollout = []\n",
    "    cumulative_return_per_ten_rollouts = []\n",
    "\n",
    "    # create saver to save model variables\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # variables used during saving the checkpoint\n",
    "    current_dir = os.getcwd()\n",
    "    max_cumulative_ret = -float(\"inf\")\n",
    "\n",
    "    total_steps = 0\n",
    "    num_rollouts = 0\n",
    "    for i in range(num_iterations):\n",
    "        while total_steps < steps_per_iteration * (i+1):\n",
    "            # update the policy with the number of previous timesteps\n",
    "            exploration_policy = lambda x: exploration_policy_offset(x, total_steps)\n",
    "\n",
    "            # perform one rollout of the policy on the environment and collect the samples\n",
    "            samples = rollout(env, sess, s_t_ph, q_func, exploration_policy)\n",
    "            total_steps += len(samples)\n",
    "            num_rollouts += 1\n",
    "\n",
    "            # update the cumulative rewards terms (so that we may visualize the \n",
    "            # improvements later)\n",
    "            cumulative_return_per_rollout.append(sum(sample[\"reward\"] for sample in samples))\n",
    "\n",
    "            # store cumulative returns in means of 10 rollouts\n",
    "            if num_rollouts % 10 == 0:\n",
    "                cumulative_return_per_ten_rollouts.append(\n",
    "                    np.mean(cumulative_return_per_rollout))\n",
    "                cumulative_return_per_rollout = []\n",
    "\n",
    "            for sample in samples:\n",
    "                # add to the replay buffer a dict containing: \"states\", \"next_states\", \n",
    "                # \"actions\", \"rewards\", and \"done_masks\". Note that the number of elements \n",
    "                # should should match the input parameter **buffer_size**.\n",
    "                ### FILL IN ###\n",
    "\n",
    "            # perform actual training here\n",
    "            for _ in range(num_opt_steps):\n",
    "                # collect a subset of samples from the replay buffer with length \n",
    "                # **batch_size**\n",
    "                ### FILL IN ###\n",
    "\n",
    "                # perform the update process by calling the update method and feeding \n",
    "                # the samples to their corresponding placeholders\n",
    "                sess.run()  ### FILL IN ###\n",
    "\n",
    "        # update the parameters of the target q function to match those of the actual\n",
    "        # q function\n",
    "        sess.run()  ### FILL IN ###\n",
    "\n",
    "        # used to monitor progress\n",
    "        print('------------------')\n",
    "        print('|the total reward of 10 rollouts was:', np.mean(cumulative_return_per_rollout[-10:]))\n",
    "        print('|the exploration fraction is:', exploration_policy(total_steps))\n",
    "        print('|number of episodes so far:', len(cumulative_return_per_rollout))\n",
    "        print('|steps so far:', total_steps)\n",
    "        print('------------------\\n')\n",
    "\n",
    "    # save the model for later viewing (save only the max)\n",
    "    if np.mean(cumulative_return_per_rollout[-10:]) > max_cumulative_ret:\n",
    "        max_cumulative_ret = np.mean(cumulative_return_per_rollout[-10:])\n",
    "        saver.save(sess, os.path.join(current_dir, \"model.ckpt\"))\n",
    "\n",
    "    return cumulative_return_per_ten_rollouts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your implementation of DQN on the \"CartPole-v0\" environment below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "\n",
    "tf.reset_default_graph()\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "avg_reward_per_iteration = train(env, learning_rate=5e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now finally ready to train your traffic signal schedule. The below cell executes one complete instance of training. Run this cell, and in the cell immediately below it, plot the average return per iteration. **Note**: If all went well, it is still possible that your algorithm's raining curve is still very noisy; for this reason, we will in the final problem look to augmentations of DQN, namely double q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "from hw2_utils import create_scenario, env_params\n",
    "from hw2_utils import sumo_params_train as sumo_params\n",
    "\n",
    "tf.reset_default_graph()\n",
    "scenario = create_scenario()\n",
    "\n",
    "# register the Flow gym environment with OpenAI gym\n",
    "env_name = \"PO_TrafficLightGridEnv\"\n",
    "try:\n",
    "    register(\n",
    "        id=env_name + \"-v0\",\n",
    "        entry_point='flow.envs:' + env_name,\n",
    "        max_episode_steps=env_params.horizon,\n",
    "        kwargs={\n",
    "            \"env_params\": env_params,\n",
    "            \"sumo_params\": sumo_params,\n",
    "            \"scenario\": scenario\n",
    "        }\n",
    "    )\n",
    "except:  # this will happen if you already registered the environment\n",
    "    pass\n",
    "env = gym.envs.make(env_name + \"-v0\")\n",
    "\n",
    "# perform the training iterations for set duration\n",
    "avg_reward_per_iteration = train(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "###### plot learning curve here ######\n",
    "######################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Visualizing Learned Control Strategies\n",
    "\n",
    "Let us now try to visualize the performance of the policy in simulation. In the below cell, we once again run the simulation as we had at the start, expect with the addition of an *rl_actions* method. This method allows us to dictate the actions of RL agents outside of the training loop. Fill in the *rl_actions* method with your new trained policy, and run the cell to visualize your traffic light policy in action. Assuming your algorithm ran as expected, the average delay you receive from the trained policy should be less than the value you received at the start of this the problem before training, meaning that your algorithm has improved traffic flow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rl_actions(state):\n",
    "    ###########################################################\n",
    "    ###### return the action from the trained Q function ######\n",
    "    ###########################################################\n",
    "    return action\n",
    "\n",
    "\n",
    "##################### DO NOT MODIFY BELOW HERE #####################\n",
    "\n",
    "import numpy as np\n",
    "from flow.envs import PO_TrafficLightGridEnv\n",
    "from flow.core.experiment import SumoExperiment\n",
    "from hw2_utils import create_scenario, env_params\n",
    "from hw2_utils import sumo_params_test as sumo_params\n",
    "\n",
    "scenario = create_scenario()\n",
    "env = PO_TrafficLightGridEnv(env_params, sumo_params, scenario)\n",
    "exp = SumoExperiment(env, scenario)\n",
    "\n",
    "# run 10 rollouts of the environment with the RL actions being specified by\n",
    "# your trained policy\n",
    "results = exp.run(10, env_params.horizon, rl_actions=rl_actions)\n",
    "\n",
    "# compute and print the new total delay\n",
    "total_delay = np.mean(results[\"returns\"])\n",
    "print(\"-----------------\")\n",
    "print('The new total return is %.3f seconds' %(total_delay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. (BONUS) Double Q Learning\n",
    "\n",
    "Several variants of DQN have arisen over the years as a means of potentially improving training performance. Once such modification is the double Q learning procedure, where the Q functions used to perform action selection and value estimation are separated in order to prevent the Q algorithm from prioritizing optimistically evaluated actions.\n",
    "\n",
    "In the below cell, extract the method from the previous parts that needs to be updated to implement double Q learning and modify the necessary lines of code. **Hint**: you only need to modify one method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "###### implement double Q learning here ######\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have implemented the double Q learning modification, test the performance of the new algorithm on the training procedure by plotting the the average and std of the training for both methods across 3 training sessions. Use default hyperparameters for all training instances. You may refer to the supplementary cell below for plotting average/range training curves, or use your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "###### train both variants and plot the training curves ######\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###### Sample Plotting Method ######\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# collect 5 noisy samples of some function (in this case y = 0.5x)\n",
    "x = np.arange(0, 100, 0.1)\n",
    "y = [0.5 * x + np.random.normal(0, 5, len(x)) for _ in range(5)]\n",
    "\n",
    "# Actual plotting past here\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "# add line for mean of y values\n",
    "plt.plot(x, np.mean(y, 0), color=\"b\")\n",
    "# fill in between min and max with lighter color\n",
    "plt.fill_between(x, np.min(y, 0), np.max(y, 0), alpha=0.25, color='b')\n",
    "plt.title(\"Sample Mean/Range Plot\", fontsize=25)\n",
    "plt.ylabel('y values', fontsize=20)\n",
    "plt.xlabel('x values', fontsize=20)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
